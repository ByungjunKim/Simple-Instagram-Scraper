{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################\n",
    "# Simple-Instagram-Scraper v1.0\n",
    "# Release: 10.11.2020\n",
    "# GitHub: do-me\n",
    "#################################\n",
    "\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import time\n",
    "import re\n",
    "from urllib.request import urlopen\n",
    "import json\n",
    "from pandas.io.json import json_normalize\n",
    "import pandas as pd, numpy as np\n",
    "import time\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import random \n",
    "import string\n",
    "\n",
    "# Parameters\n",
    "\n",
    "# CRUCIAL PARAMS\n",
    "# directory to chromedriver or geckodriver, find chromedriver here: https://chromedriver.chromium.org/\n",
    "browser = webdriver.Chrome(\"yourpath\")\n",
    "\n",
    "# user credentials\n",
    "username = \"username\"\n",
    "userpassword = \"password\"\n",
    "\n",
    "# which page?\n",
    "pagetoscrape = \"https://www.instagram.com/explore/locations/118546/thessaloniki/\" # either hashtag, location id or user account possible\n",
    "\n",
    "\n",
    "#---------------------------------------------------------------\n",
    "\n",
    "# OPTIONAL PARAMS\n",
    "\n",
    "# maximum posts to scrape\n",
    "maxiter = 10000\n",
    "\n",
    "# quite crucial but subject to trial and error due to unknown Instagram blocking policy: breaks\n",
    "# set a random break duration for every iteration after opening one post and before going to the next one\n",
    "short_pauseduration_min = 1.5 # seconds \n",
    "short_pauseduration_max = 2.3 # seconds\n",
    "\n",
    "# set a random break duration for longer breaks...\n",
    "long_pauseduration_min = 4.8 # seconds \n",
    "long_pauseduration_max = 10.5 # seconds\n",
    "\n",
    "# ...for the following random iterations (number of iterations = index of scraped posts)\n",
    "pauselist = random.sample(range(10, 10000), 400) # between 10 and 10000 generate list of 500 values # randomList.sort() for sorting\n",
    "pauselist.append([x + int(random.uniform(1,10)) for x in np.arange(20, 10000, 50).tolist()]) # just to make sure: add list with values every 51th to 60th iteration  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### some functions #####\n",
    "\n",
    "def brsel(obj): # browser select, convenience function\n",
    "    global browser\n",
    "    try:\n",
    "        return browser.find_elements_by_css_selector(obj)\n",
    "    except:\n",
    "        return np.nan\n",
    "    \n",
    "def long_pauseduration():\n",
    "    return random.uniform(long_pauseduration_min, long_pauseduration_max)\n",
    "\n",
    "def short_pauseduration():\n",
    "    return random.uniform(short_pauseduration_min, short_pauseduration_max)\n",
    "\n",
    "def nextpost():\n",
    "    brsel(\".coreSpriteRightPaginationArrow\")[0].click()\n",
    "\n",
    "def previouspost():\n",
    "    brsel(\".coreSpriteLeftPaginationArrow\")[0].click()\n",
    "\n",
    "def gibberish():\n",
    "    return ''.join(random.choice(string.ascii_lowercase) for _ in range(10))\n",
    "\n",
    "def parsepost(): # parse function when post is displayed in gallery view, could also be executed manually\n",
    "    global browser\n",
    "    \n",
    "    # values always existent\n",
    "    p_time = brsel('time')[0].get_attribute('datetime')\n",
    "    p_user_name = brsel('.ZIAjV')[0].text \n",
    "    p_user_id = brsel('.ZIAjV')[0].get_attribute('href').split(\"/\")[-2] \n",
    "    p_post_id = browser.current_url.split(\"/\")[-2]\n",
    "    \n",
    "    # values sometimes existent wrap in try except function\n",
    "    p_loc_name = np.nan\n",
    "    p_loc_slug = np.nan\n",
    "    p_loc_id = np.nan\n",
    "    p_likes = np.nan\n",
    "    p_clicks = np.nan\n",
    "    p_text = np.nan\n",
    "    p_hashtags = np.nan\n",
    "    \n",
    "    if len(brsel('.O4GlU'))>0: # if location exists\n",
    "        p_loc_name = brsel('.O4GlU')[0].text\n",
    "        p_loc_slug = brsel('.O4GlU')[0].get_attribute('href').split(\"/\")[-2]\n",
    "        p_loc_id = brsel('.O4GlU')[0].get_attribute('href').split(\"/\")[-3]\n",
    "        \n",
    "    if len(brsel('.Nm9Fw button span'))>0: # likes\n",
    "        p_likes = brsel('.Nm9Fw button span')[0].text # likes # can be non\n",
    "           \n",
    "    if len(brsel('.vcOH2'))>0: # clicks\n",
    "        p_clicks = brsel('.vcOH2')[0].text  \n",
    "        \n",
    "    if len(brsel('ul li'))>0:\n",
    "        p_text = brsel('ul li span')[1].text # full text including hashtags\n",
    "        \n",
    "        if len(brsel('ul li')[0].find_elements_by_css_selector('span')) > 0: # only hashtags\n",
    "            if len(brsel('ul li span')[1].find_elements_by_css_selector('a'))>0:\n",
    "                p_hashtags = [x.text for x in brsel('ul li span')[1].find_elements_by_css_selector('a')]         \n",
    "            \n",
    "    return [p_time,p_user_name,p_user_id,p_post_id,p_loc_name,p_loc_slug,p_loc_id,p_likes,p_clicks,p_text,p_hashtags]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# login\n",
    "browser.get('https://www.instagram.com/accounts/login/') # open login page and log in\n",
    "time.sleep(3)\n",
    "browser.find_elements_by_css_selector('.bIiDR')[0].click() # confirm cookies\n",
    "time.sleep(1)\n",
    "\n",
    "emailInput = browser.find_elements_by_css_selector('form input')[0]\n",
    "passwordInput = browser.find_elements_by_css_selector('form input')[1]\n",
    "\n",
    "emailInput.send_keys(username)\n",
    "passwordInput.send_keys(userpassword)\n",
    "passwordInput.send_keys(Keys.ENTER)\n",
    "\n",
    "time.sleep(3)\n",
    "browser.find_elements_by_css_selector('button')[1].click() # dont save user credentials (not possible)\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize page\n",
    "browser.get(pagetoscrape)\n",
    "time.sleep(2)\n",
    "brsel('._9AhH0')[9].click()  # get first post ignoring top posts\n",
    "\n",
    "# until here one could go manually correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts = [] # emtpy list \n",
    "# execute this cell only once in the beginning \n",
    "# if for some reason the loop in the next cell stops, you can simple reexecute the next cell\n",
    "# this list then contains the previously scraped information and adds new posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "while i < maxiter:\n",
    "    print(\"Iteration: \" + str(i), end=\"\\r\")\n",
    "    \n",
    "    # if not loading go back and forth\n",
    "    # if fails again, set np.nan\n",
    "    try: \n",
    "        currpost = parsepost()\n",
    "    except IndexError:\n",
    "        previouspost()\n",
    "        time.sleep(3)\n",
    "        nextpost()\n",
    "        time.sleep(3)\n",
    "        try: \n",
    "            currpost = parsepost()\n",
    "        except IndexError:\n",
    "            p_post_id = browser.current_url.split(\"/\")[-2]\n",
    "            posts.append([np.nan,np.nan,np.nan,p_post_id,np.nan,np.nan,np.nan,np.nan,np.nan,np.nan,np.nan])\n",
    "            if i in pauselist:\n",
    "                time.sleep(long_pauseduration())\n",
    "\n",
    "            if len(brsel(\".coreSpriteRightPaginationArrow\"))==0: # break if come to the end or blocked entirely\n",
    "                print(\"Ended at iteration:\" +str(i))\n",
    "                break\n",
    "\n",
    "            nextpost()\n",
    "            time.sleep(short_pauseduration())\n",
    "            i += 1\n",
    "            continue\n",
    "    \n",
    "    posts.append(currpost)\n",
    "    \n",
    "    if i in pauselist:\n",
    "        time.sleep(long_pauseduration())\n",
    "    \n",
    "    if len(brsel(\".coreSpriteRightPaginationArrow\"))==0: # break if come to the end or blocked entirely\n",
    "        print(\"Ended at iteration:\" +str(i))\n",
    "        break\n",
    "        \n",
    "    if i % 11 == 0: # every nth iteration\n",
    "        try:\n",
    "            brsel('form')[0].click()\n",
    "            try:\n",
    "                brsel('form textarea')[0].send_keys(gibberish())\n",
    "            except IndexError:\n",
    "                time.sleep(0.3)          \n",
    "        except:\n",
    "            time.sleep(0.2)\n",
    "        time.sleep(1.2)\n",
    "\n",
    "     \n",
    "    nextpost()\n",
    "    time.sleep(short_pauseduration())\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(posts)\n",
    "pd.set_option('display.max_rows', df.shape[0]+1) # display all rows\n",
    "df   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
